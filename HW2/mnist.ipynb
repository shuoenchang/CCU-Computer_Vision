{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\").values\n",
    "train = shuffle(train)\n",
    "test  = pd.read_csv(\"test.csv\").values\n",
    "\n",
    "validation = train[0:4200]\n",
    "train = train[4200:42000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Converting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([37800, 1, 28, 28]) torch.Size([37800, 1])\n"
     ]
    }
   ],
   "source": [
    "X_data  = train[:, 1:].reshape(train.shape[0], 1, 28, 28)\n",
    "X_data  = X_data.astype(float)\n",
    "X_data /= 255.0\n",
    "X_data  = torch.from_numpy(X_data);\n",
    "X_label = train[:,0];\n",
    "X_label = X_label.astype(int);\n",
    "X_label = torch.from_numpy(X_label);\n",
    "X_label = X_label.view(train.shape[0],-1);\n",
    "print (X_data.size(), X_label.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4200, 1, 28, 28]) torch.Size([4200, 1])\n"
     ]
    }
   ],
   "source": [
    "Y_data  = validation[:, 1:].reshape(validation.shape[0], 1, 28, 28)\n",
    "Y_data  = Y_data.astype(float)\n",
    "Y_data /= 255.0\n",
    "Y_data  = torch.from_numpy(Y_data);\n",
    "Y_label = validation[:,0];\n",
    "Y_label = Y_label.astype(int);\n",
    "Y_label = torch.from_numpy(Y_label);\n",
    "Y_label = Y_label.view(validation.shape[0],-1);\n",
    "print (Y_data.size(), Y_label.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2738273c358>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_label[0].item())\n",
    "plt.imshow(X_data[0][0,:,:],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(data, label, net):\n",
    "    nb_data = data.shape[0]\n",
    "    nb_batch = 10\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    final_prediction = Variable(torch.zeros(nb_data, dtype=torch.int), requires_grad = False)\n",
    "    if use_gpu:\n",
    "        final_prediction = final_prediction.cuda()\n",
    "    for each_sample in range(0, nb_data, nb_batch):\n",
    "        sample_data = Variable(data[each_sample:each_sample+nb_batch].clone())\n",
    "        sample_data = sample_data.type(torch.FloatTensor)\n",
    "        \n",
    "        sample_label = Variable(label[each_sample:each_sample+nb_batch].clone(), requires_grad = False)\n",
    "        sample_label = sample_label.type(torch.LongTensor)\n",
    "        if use_gpu:\n",
    "            sample_data = sample_data.cuda()\n",
    "            sample_label = sample_label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        sample_out   = net(sample_data)\n",
    "        sample_label = sample_label.view(nb_batch)\n",
    "        sample_loss  = criterion(sample_out, sample_label)      \n",
    "        loss = loss+sample_loss\n",
    "        \n",
    "        _, pred = torch.max(sample_out, 1)\n",
    "        final_prediction[each_sample:each_sample+nb_batch] = pred\n",
    "    correct = 0\n",
    "    if use_gpu:\n",
    "        label = Variable(label).cuda()\n",
    "    for i in range(nb_data):\n",
    "        if final_prediction[i] == label[i]:\n",
    "            correct += 1\n",
    "            \n",
    "    loss = loss/(nb_data/nb_batch)\n",
    "    accuracy = correct/nb_data*100\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-1. Train for LeNet5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, (5,5), padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, (5,5))\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = LeNet5()\n",
    "print (net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE GPU\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    net = net.cuda()\n",
    "    print ('USE GPU')\n",
    "else:\n",
    "    print ('USE CPU')\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Train = 2.280325, Val = 2.233967(38.666667%)\n",
      "Epoch = 2, Train = 1.528717, Val = 0.636360(80.690476%)\n",
      "Epoch = 3, Train = 0.474743, Val = 0.383500(88.380952%)\n",
      "Epoch = 4, Train = 0.339689, Val = 0.297159(91.380952%)\n",
      "Epoch = 5, Train = 0.276905, Val = 0.246397(93.190476%)\n",
      "Epoch = 6, Train = 0.233288, Val = 0.208009(94.166667%)\n",
      "Epoch = 7, Train = 0.200484, Val = 0.180420(94.880952%)\n",
      "Epoch = 8, Train = 0.175219, Val = 0.159438(95.357143%)\n",
      "Epoch = 9, Train = 0.155352, Val = 0.142863(95.904762%)\n",
      "Epoch = 10, Train = 0.139546, Val = 0.129927(96.261905%)\n",
      "Epoch = 11, Train = 0.127192, Val = 0.120201(96.452381%)\n",
      "Epoch = 12, Train = 0.117183, Val = 0.112537(96.761905%)\n",
      "Epoch = 13, Train = 0.108896, Val = 0.106315(96.857143%)\n",
      "Epoch = 14, Train = 0.101966, Val = 0.101436(97.023810%)\n",
      "Epoch = 15, Train = 0.095998, Val = 0.097267(97.000000%)\n",
      "Epoch = 16, Train = 0.090854, Val = 0.093632(97.071429%)\n",
      "Epoch = 17, Train = 0.086337, Val = 0.090415(97.285714%)\n",
      "Epoch = 18, Train = 0.082359, Val = 0.087659(97.285714%)\n",
      "Epoch = 19, Train = 0.078855, Val = 0.085236(97.404762%)\n",
      "Epoch = 20, Train = 0.075692, Val = 0.083489(97.547619%)\n",
      "Epoch = 21, Train = 0.072939, Val = 0.081388(97.642857%)\n",
      "Epoch = 22, Train = 0.070290, Val = 0.079923(97.666667%)\n",
      "Epoch = 23, Train = 0.067887, Val = 0.078231(97.690476%)\n",
      "Epoch = 24, Train = 0.065588, Val = 0.076948(97.738095%)\n",
      "Epoch = 25, Train = 0.063425, Val = 0.075489(97.785714%)\n",
      "Epoch = 26, Train = 0.061437, Val = 0.074497(97.809524%)\n",
      "Epoch = 27, Train = 0.059482, Val = 0.073208(97.880952%)\n",
      "Epoch = 28, Train = 0.057646, Val = 0.072041(97.904762%)\n",
      "Epoch = 29, Train = 0.055869, Val = 0.071128(97.880952%)\n",
      "Epoch = 30, Train = 0.054285, Val = 0.070152(97.904762%)\n",
      "Epoch = 31, Train = 0.052676, Val = 0.069194(97.880952%)\n",
      "Epoch = 32, Train = 0.051184, Val = 0.068321(97.928571%)\n",
      "Epoch = 33, Train = 0.049750, Val = 0.067582(97.952381%)\n",
      "Epoch = 34, Train = 0.048398, Val = 0.066929(98.000000%)\n",
      "Epoch = 35, Train = 0.047065, Val = 0.066387(98.047619%)\n",
      "Epoch = 36, Train = 0.045759, Val = 0.065198(98.119048%)\n",
      "Epoch = 37, Train = 0.044469, Val = 0.065117(98.071429%)\n",
      "Epoch = 38, Train = 0.043253, Val = 0.064632(98.119048%)\n",
      "Epoch = 39, Train = 0.042039, Val = 0.064220(98.142857%)\n",
      "Epoch = 40, Train = 0.040912, Val = 0.064060(98.142857%)\n",
      "Epoch = 41, Train = 0.039865, Val = 0.063642(98.190476%)\n",
      "Epoch = 42, Train = 0.038811, Val = 0.063291(98.190476%)\n",
      "Epoch = 43, Train = 0.037803, Val = 0.063180(98.190476%)\n",
      "Epoch = 44, Train = 0.036800, Val = 0.062602(98.190476%)\n",
      "Epoch = 45, Train = 0.035836, Val = 0.062216(98.238095%)\n",
      "Epoch = 46, Train = 0.034855, Val = 0.062226(98.214286%)\n",
      "Epoch = 47, Train = 0.034029, Val = 0.061812(98.261905%)\n",
      "Epoch = 48, Train = 0.033114, Val = 0.061802(98.214286%)\n",
      "Epoch = 49, Train = 0.032289, Val = 0.061585(98.238095%)\n",
      "Epoch = 50, Train = 0.031462, Val = 0.061510(98.238095%)\n"
     ]
    }
   ],
   "source": [
    "nb_train = train.shape[0]\n",
    "nb_epoch = 50\n",
    "nb_index = 0\n",
    "nb_batch = 10\n",
    "\n",
    "for epoch in range(nb_epoch):\n",
    "    net.eval()\n",
    "    train_loss = 0\n",
    "    for nb_index in range(0, nb_train, nb_batch):\n",
    "        mini_data  = Variable(X_data[nb_index:(nb_index+nb_batch)].clone())\n",
    "        mini_label = Variable(X_label[nb_index:(nb_index+nb_batch)].clone(), requires_grad = False)\n",
    "        mini_data  = mini_data.type(torch.FloatTensor)\n",
    "        mini_label = mini_label.type(torch.LongTensor)\n",
    "        if use_gpu:\n",
    "            mini_data  = mini_data.cuda()\n",
    "            mini_label = mini_label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        mini_out   = net(mini_data)\n",
    "        mini_label = mini_label.view(nb_batch)\n",
    "        mini_loss  = criterion(mini_out, mini_label)\n",
    "        mini_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += mini_loss\n",
    "    train_loss = train_loss/(nb_train/nb_batch)\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        val_loss, val_acc = evaluation(Y_data, Y_label, net)\n",
    "        print(\"Epoch = %d, Train = %f, Val = %f(%f%%)\" %(epoch+1, train_loss.data.item(), val_loss.data.item(), val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-1. Testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28000, 1, 28, 28])\n",
      "Total tested = 2000\n",
      "Total tested = 4000\n",
      "Total tested = 6000\n",
      "Total tested = 8000\n",
      "Total tested = 10000\n",
      "Total tested = 12000\n",
      "Total tested = 14000\n",
      "Total tested = 16000\n",
      "Total tested = 18000\n",
      "Total tested = 20000\n",
      "Total tested = 22000\n",
      "Total tested = 24000\n",
      "Total tested = 26000\n",
      "Total tested = 28000\n"
     ]
    }
   ],
   "source": [
    "Y_data  = test.reshape(test.shape[0], 1, 28, 28)\n",
    "Y_data  = Y_data.astype(float)\n",
    "Y_data /= 255.0\n",
    "Y_data  = torch.from_numpy(Y_data);\n",
    "print (Y_data.size())\n",
    "nb_test = test.shape[0]\n",
    "\n",
    "net.eval()\n",
    "\n",
    "final_prediction = np.ndarray(shape = (nb_test, 2), dtype=int)\n",
    "for each_sample in range(nb_test):\n",
    "    sample_data = Variable(Y_data[each_sample:each_sample+1].clone())\n",
    "    sample_data = sample_data.type(torch.FloatTensor)\n",
    "    if use_gpu:\n",
    "        sample_data = sample_data.cuda()\n",
    "    sample_out = net(sample_data)\n",
    "    _, pred = torch.max(sample_out, 1)\n",
    "    final_prediction[each_sample][0] = 1 + each_sample\n",
    "    final_prediction[each_sample][1] = pred.data\n",
    "    if (each_sample + 1) % 2000 == 0:\n",
    "        print(\"Total tested = %d\" %(each_sample + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(final_prediction, dtype=int, columns=['ImageId', 'Label'])\n",
    "submission.to_csv('pytorch_LeNet5.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-2. Train for LeNet7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet7(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet7, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, (5,5), padding=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, (5,5))\n",
    "        self.conv3 = nn.Conv2d(16, 26, (5,5))\n",
    "        self.fc0   = nn.Linear(26, 16*5*5)\n",
    "        self.fc1   = nn.Linear(16*5*5, 120)\n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc0(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet7(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(16, 26, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc0): Linear(in_features=26, out_features=400, bias=True)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = LeNet7()\n",
    "print (net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE GPU\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    net = net.cuda()\n",
    "    print ('USE GPU')\n",
    "else:\n",
    "    print ('USE CPU')\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4200, 1, 28, 28]) torch.Size([4200, 1])\n"
     ]
    }
   ],
   "source": [
    "Y_data  = validation[:, 1:].reshape(validation.shape[0], 1, 28, 28)\n",
    "Y_data  = Y_data.astype(float)\n",
    "Y_data /= 255.0\n",
    "Y_data  = torch.from_numpy(Y_data);\n",
    "Y_label = validation[:,0];\n",
    "Y_label = Y_label.astype(int);\n",
    "Y_label = torch.from_numpy(Y_label);\n",
    "Y_label = Y_label.view(validation.shape[0],-1);\n",
    "print (Y_data.size(), Y_label.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, Train = 2.301973, Val = 2.300755(10.880952%)\n",
      "Epoch = 2, Train = 2.301140, Val = 2.299932(11.738095%)\n",
      "Epoch = 3, Train = 2.300627, Val = 2.299316(11.738095%)\n",
      "Epoch = 4, Train = 2.300126, Val = 2.298666(11.738095%)\n",
      "Epoch = 5, Train = 2.299430, Val = 2.297744(11.738095%)\n",
      "Epoch = 6, Train = 2.298233, Val = 2.296066(11.738095%)\n",
      "Epoch = 7, Train = 2.295747, Val = 2.292399(11.738095%)\n",
      "Epoch = 8, Train = 2.289316, Val = 2.281463(11.738095%)\n",
      "Epoch = 9, Train = 2.262844, Val = 2.219127(42.285714%)\n",
      "Epoch = 10, Train = 1.726378, Val = 1.057977(63.119048%)\n",
      "Epoch = 11, Train = 0.736975, Val = 0.537991(82.904762%)\n",
      "Epoch = 12, Train = 0.454492, Val = 0.386562(88.357143%)\n",
      "Epoch = 13, Train = 0.348104, Val = 0.295523(91.071429%)\n",
      "Epoch = 14, Train = 0.274956, Val = 0.236894(92.857143%)\n",
      "Epoch = 15, Train = 0.223962, Val = 0.196807(94.119048%)\n",
      "Epoch = 16, Train = 0.188671, Val = 0.168120(95.000000%)\n",
      "Epoch = 17, Train = 0.163899, Val = 0.148708(95.476190%)\n",
      "Epoch = 18, Train = 0.146044, Val = 0.134110(95.809524%)\n",
      "Epoch = 19, Train = 0.132608, Val = 0.123796(96.190476%)\n",
      "Epoch = 20, Train = 0.122088, Val = 0.115671(96.500000%)\n",
      "Epoch = 21, Train = 0.113545, Val = 0.109273(96.690476%)\n",
      "Epoch = 22, Train = 0.106365, Val = 0.104436(96.738095%)\n",
      "Epoch = 23, Train = 0.100290, Val = 0.099117(96.785714%)\n",
      "Epoch = 24, Train = 0.095062, Val = 0.095094(96.952381%)\n",
      "Epoch = 25, Train = 0.090532, Val = 0.092065(97.166667%)\n",
      "Epoch = 26, Train = 0.086538, Val = 0.088680(97.333333%)\n",
      "Epoch = 27, Train = 0.082947, Val = 0.085999(97.452381%)\n",
      "Epoch = 28, Train = 0.079792, Val = 0.083622(97.619048%)\n",
      "Epoch = 29, Train = 0.076895, Val = 0.081620(97.714286%)\n",
      "Epoch = 30, Train = 0.074312, Val = 0.079620(97.785714%)\n",
      "Epoch = 31, Train = 0.071925, Val = 0.077861(97.809524%)\n",
      "Epoch = 32, Train = 0.069713, Val = 0.076135(97.904762%)\n",
      "Epoch = 33, Train = 0.067626, Val = 0.074702(97.880952%)\n",
      "Epoch = 34, Train = 0.065628, Val = 0.073319(97.952381%)\n",
      "Epoch = 35, Train = 0.063751, Val = 0.072245(97.976190%)\n",
      "Epoch = 36, Train = 0.062094, Val = 0.071125(97.952381%)\n",
      "Epoch = 37, Train = 0.060497, Val = 0.069951(97.928571%)\n",
      "Epoch = 38, Train = 0.058989, Val = 0.068686(97.952381%)\n",
      "Epoch = 39, Train = 0.057549, Val = 0.067518(97.976190%)\n",
      "Epoch = 40, Train = 0.056191, Val = 0.066693(97.976190%)\n",
      "Epoch = 41, Train = 0.054910, Val = 0.065832(98.023810%)\n",
      "Epoch = 42, Train = 0.053662, Val = 0.064988(97.976190%)\n",
      "Epoch = 43, Train = 0.052485, Val = 0.064388(98.000000%)\n",
      "Epoch = 44, Train = 0.051309, Val = 0.063494(98.023810%)\n",
      "Epoch = 45, Train = 0.050235, Val = 0.062809(98.023810%)\n",
      "Epoch = 46, Train = 0.049187, Val = 0.062080(98.095238%)\n",
      "Epoch = 47, Train = 0.048142, Val = 0.061244(98.119048%)\n",
      "Epoch = 48, Train = 0.047137, Val = 0.060745(98.119048%)\n",
      "Epoch = 49, Train = 0.046137, Val = 0.060429(98.095238%)\n",
      "Epoch = 50, Train = 0.045197, Val = 0.059783(98.119048%)\n"
     ]
    }
   ],
   "source": [
    "nb_train = train.shape[0]\n",
    "nb_epoch = 50\n",
    "nb_index = 0\n",
    "nb_batch = 10\n",
    "\n",
    "for epoch in range(nb_epoch):\n",
    "    net.eval()\n",
    "    train_loss = 0\n",
    "    for nb_index in range(0, nb_train, nb_batch):\n",
    "        mini_data  = Variable(X_data[nb_index:(nb_index+nb_batch)].clone())\n",
    "        mini_label = Variable(X_label[nb_index:(nb_index+nb_batch)].clone(), requires_grad = False)\n",
    "        mini_data  = mini_data.type(torch.FloatTensor)\n",
    "        mini_label = mini_label.type(torch.LongTensor)\n",
    "        if use_gpu:\n",
    "            mini_data  = mini_data.cuda()\n",
    "            mini_label = mini_label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        mini_out   = net(mini_data)\n",
    "        mini_label = mini_label.view(nb_batch)\n",
    "        mini_loss  = criterion(mini_out, mini_label)\n",
    "        mini_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += mini_loss\n",
    "    train_loss = train_loss/(nb_train/nb_batch)\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        val_loss, val_acc = evaluation(Y_data, Y_label, net)\n",
    "        print(\"Epoch = %d, Train = %f, Val = %f(%f%%)\" %(epoch+1, train_loss.data.item(), val_loss.data.item(), val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4-2. Testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28000, 1, 28, 28])\n",
      "Total tested = 2000\n",
      "Total tested = 4000\n",
      "Total tested = 6000\n",
      "Total tested = 8000\n",
      "Total tested = 10000\n",
      "Total tested = 12000\n",
      "Total tested = 14000\n",
      "Total tested = 16000\n",
      "Total tested = 18000\n",
      "Total tested = 20000\n",
      "Total tested = 22000\n",
      "Total tested = 24000\n",
      "Total tested = 26000\n",
      "Total tested = 28000\n"
     ]
    }
   ],
   "source": [
    "Y_data  = test.reshape(test.shape[0], 1, 28, 28)\n",
    "Y_data  = Y_data.astype(float)\n",
    "Y_data /= 255.0\n",
    "Y_data  = torch.from_numpy(Y_data);\n",
    "print (Y_data.size())\n",
    "nb_test = test.shape[0]\n",
    "\n",
    "net.eval()\n",
    "\n",
    "final_prediction = np.ndarray(shape = (nb_test, 2), dtype=int)\n",
    "for each_sample in range(nb_test):\n",
    "    sample_data = Variable(Y_data[each_sample:each_sample+1].clone())\n",
    "    sample_data = sample_data.type(torch.FloatTensor)\n",
    "    if use_gpu:\n",
    "        sample_data = sample_data.cuda()\n",
    "    sample_out = net(sample_data)\n",
    "    _, pred = torch.max(sample_out, 1)\n",
    "    final_prediction[each_sample][0] = 1 + each_sample\n",
    "    final_prediction[each_sample][1] = pred.data\n",
    "    if (each_sample + 1) % 2000 == 0:\n",
    "        print(\"Total tested = %d\" %(each_sample + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(final_prediction, dtype=int, columns=['ImageId', 'Label'])\n",
    "submission.to_csv('pytorch_LeNet7.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML2018]",
   "language": "python",
   "name": "conda-env-ML2018-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
